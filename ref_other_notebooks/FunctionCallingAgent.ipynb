{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GWvKKFRdxvP"
      },
      "source": [
        "# FunctionCallingAgent\n",
        "\n",
        "In this notebook we will look into experimenting with `FunctionCallingAgent` with Simple Calculator Tools and RAG QueryEngine Tools.\n",
        "\n",
        "`FunctionCallingAgent` uses LLM function calling capabilities to complete the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1rb_v0OfIPS"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index\n",
        "!pip install llama-index-llms-anthropic\n",
        "!pip install llama-index-llms-mistralai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH47QWjodBbK"
      },
      "source": [
        "## Simple Calculator Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd8MzkGuLhtq"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.agent import ReActAgent\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.llms.anthropic import Anthropic\n",
        "from llama_index.llms.mistralai import MistralAI\n",
        "from llama_index.core.llms import ChatMessage\n",
        "from llama_index.core.tools import BaseTool, FunctionTool\n",
        "from llama_index.core.agent import FunctionCallingAgentWorker, AgentRunner\n",
        "from llama_index.core.agent import AgentRunner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiPWsI6PdHRr"
      },
      "source": [
        "### Define Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQW2ccGlLrg7"
      },
      "outputs": [],
      "source": [
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two integers and returns the result integer\"\"\"\n",
        "    return a * b\n",
        "\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
        "    return a + b\n",
        "\n",
        "def subtract(a: int, b: int) -> int:\n",
        "    \"\"\"Subtract two integers and returns the result integer\"\"\"\n",
        "    return a - b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp4NnpPkLycF"
      },
      "outputs": [],
      "source": [
        "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
        "add_tool = FunctionTool.from_defaults(fn=add)\n",
        "subtract_tool = FunctionTool.from_defaults(fn=subtract)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCk_5CGqL-zQ"
      },
      "source": [
        "####  OpenAI GPT-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3oXEzTVMca7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = 'YOUR OPENAI API KEY'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXXBY5Y9L1Qt"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(model=\"gpt-4\")\n",
        "\n",
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    [multiply_tool, add_tool, subtract_tool],\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    allow_parallel_tool_calls=False,\n",
        ")\n",
        "agent = AgentRunner(agent_worker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NweG3sWNMkbF",
        "outputId": "6fb3653e-40e3-4ce2-9b1e-fe02f371a772"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: What is 20+(2*4)? Calculate step by step.\n",
            "=== Calling Function ===\n",
            "Calling function: multiply with args: {\"a\": 2, \"b\": 4}\n",
            "=== Function Output ===\n",
            "8\n",
            "=== Calling Function ===\n",
            "Calling function: add with args: {\"a\": 20, \"b\": 8}\n",
            "=== Function Output ===\n",
            "28\n",
            "=== LLM Response ===\n",
            "The result of 20+(2*4) is 28.\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"What is 20+(2*4)? Calculate step by step.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArPLRv7hOfdr",
        "outputId": "9b041d59-63dc-4c00-a9f2-09d387eb2731"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "assistant: The result of 20+(2*4) is 28.\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdfa218bMp9o",
        "outputId": "a1244513-4db0-4c47-818a-f20b06ed369f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: 40 + (100 - 30)*5 ? Calculate step by step.\n",
            "=== Calling Function ===\n",
            "Calling function: subtract with args: {\"a\": 100, \"b\": 30}\n",
            "=== Function Output ===\n",
            "70\n",
            "=== Calling Function ===\n",
            "Calling function: multiply with args: {\"a\": 70, \"b\": 5}\n",
            "=== Function Output ===\n",
            "350\n",
            "=== Calling Function ===\n",
            "Calling function: add with args: {\"a\": 40, \"b\": 350}\n",
            "=== Function Output ===\n",
            "390\n",
            "=== LLM Response ===\n",
            "The result of 40 + (100 - 30)*5 is 390.\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"40 + (100 - 30)*5 ? Calculate step by step.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjE4PjBJPG4O",
        "outputId": "0da66030-79fc-4750-c157-2de7958a47bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "assistant: The result of 40 + (100 - 30)*5 is 390.\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8Acucy7MEku"
      },
      "source": [
        "#### Anthropic Sonnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NK3rHgyMMjyn"
      },
      "outputs": [],
      "source": [
        "os.environ['ANTHROPIC_API_KEY'] = 'YOUR ANTHROPIC API KEY'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iPdYMJ4MDLm"
      },
      "outputs": [],
      "source": [
        "llm = Anthropic(model=\"claude-3-sonnet-20240229\")\n",
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    [multiply_tool, add_tool, subtract_tool],\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    allow_parallel_tool_calls=False,\n",
        ")\n",
        "agent = AgentRunner(agent_worker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NZjCVgQRWs4",
        "outputId": "9c587542-4c96-4b38-89bb-8ad03bf19198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: What is 20+(2*4)? Calculate step by step.\n",
            "=== LLM Response ===\n",
            "Okay, let's calculate 20 + (2 * 4) step-by-step:\n",
            "=== Calling Function ===\n",
            "Calling function: multiply with args: {\"a\": 2, \"b\": 4}\n",
            "=== Function Output ===\n",
            "8\n",
            "=== LLM Response ===\n",
            "First, we multiply 2 * 4 to get 8.\n",
            "\n",
            "Then:\n",
            "=== Calling Function ===\n",
            "Calling function: add with args: {\"a\": 20, \"b\": 8}\n",
            "=== Function Output ===\n",
            "28\n",
            "=== LLM Response ===\n",
            "We add 20 + 8 to get the final result of 28.\n",
            "\n",
            "Therefore, the step-by-step calculation of 20 + (2 * 4) is:\n",
            "1) 2 * 4 = 8\n",
            "2) 20 + 8 = 28\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"What is 20+(2*4)? Calculate step by step.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA0xh4n3Radt",
        "outputId": "140a857f-4115-41ed-ead0-2b75c8285151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "assistant: We add 20 + 8 to get the final result of 28.\n",
            "\n",
            "Therefore, the step-by-step calculation of 20 + (2 * 4) is:\n",
            "1) 2 * 4 = 8\n",
            "2) 20 + 8 = 28\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOmCX2bpRp71",
        "outputId": "fbce9678-c2f1-4204-dca5-4e222471b3a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: 40 + (100 - 30)*5 ? Calculate step by step.\n",
            "=== LLM Response ===\n",
            "Sure, let's calculate 40 + (100 - 30) * 5 step-by-step:\n",
            "\n",
            "First, we calculate (100 - 30):\n",
            "=== Calling Function ===\n",
            "Calling function: subtract with args: {\"a\": 100, \"b\": 30}\n",
            "=== Function Output ===\n",
            "70\n",
            "=== LLM Response ===\n",
            "So 100 - 30 = 70\n",
            "\n",
            "Next, we multiply 70 by 5:\n",
            "=== Calling Function ===\n",
            "Calling function: multiply with args: {\"a\": 70, \"b\": 5}\n",
            "=== Function Output ===\n",
            "350\n",
            "=== LLM Response ===\n",
            "So 70 * 5 = 350\n",
            "\n",
            "Finally, we add 40 to 350:\n",
            "=== Calling Function ===\n",
            "Calling function: add with args: {\"a\": 40, \"b\": 350}\n",
            "=== Function Output ===\n",
            "390\n",
            "=== LLM Response ===\n",
            "Therefore, the step-by-step calculation of 40 + (100 - 30) * 5 is:\n",
            "1) 100 - 30 = 70\n",
            "2) 70 * 5 = 350 \n",
            "3) 40 + 350 = 390\n",
            "\n",
            "The final result is 390.\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"40 + (100 - 30)*5 ? Calculate step by step.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCQdzp4BRrSF",
        "outputId": "73692f35-0484-47a7-ac0a-5a5f21c8ca1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "assistant: Therefore, the step-by-step calculation of 40 + (100 - 30) * 5 is:\n",
            "1) 100 - 30 = 70\n",
            "2) 70 * 5 = 350 \n",
            "3) 40 + 350 = 390\n",
            "\n",
            "The final result is 390.\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MuNIhZzMHcm"
      },
      "source": [
        "#### MistralAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVT1NS2RJFvB"
      },
      "outputs": [],
      "source": [
        "os.environ['MISTRAL_API_KEY'] = 'YOUR MISTRALAI API KEY'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKKHSQPEJHdY"
      },
      "outputs": [],
      "source": [
        "llm = MistralAI(model=\"mistral-large-latest\")\n",
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    [multiply_tool, add_tool, subtract_tool],\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    allow_parallel_tool_calls=False,\n",
        ")\n",
        "agent = AgentRunner(agent_worker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XPgLksgJI5B",
        "outputId": "7e5a5804-cb06-4bbd-eabe-5c05b43b25b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: What is 20+(2*4)?\n",
            "=== Calling Function ===\n",
            "Calling function: multiply with args: {\"a\": 2, \"b\": 4}\n",
            "=== Function Output ===\n",
            "8\n",
            "=== Calling Function ===\n",
            "Calling function: add with args: {\"a\": 20, \"b\": 8}\n",
            "=== Function Output ===\n",
            "28\n",
            "=== LLM Response ===\n",
            "The result of 20+(2*4) is 28.\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"What is 20+(2*4)?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUhJCwliJLmg",
        "outputId": "df8141d0-ef22-4f8b-c485-484761801ea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "assistant: The result of 20+(2*4) is 28.\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMlBJu2vdUU2"
      },
      "source": [
        "## RAG QueryEngine Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEY6G0JtXuMo"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import (\n",
        "    SimpleDirectoryReader,\n",
        "    VectorStoreIndex,\n",
        "    StorageContext,\n",
        "    load_index_from_storage,\n",
        ")\n",
        "\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7x3grUzbL5w"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    storage_context = StorageContext.from_defaults(\n",
        "        persist_dir=\"./storage/lyft\"\n",
        "    )\n",
        "    lyft_index = load_index_from_storage(storage_context)\n",
        "\n",
        "    storage_context = StorageContext.from_defaults(\n",
        "        persist_dir=\"./storage/uber\"\n",
        "    )\n",
        "    uber_index = load_index_from_storage(storage_context)\n",
        "\n",
        "    index_loaded = True\n",
        "except:\n",
        "    index_loaded = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUnO5ZX8dYJA"
      },
      "source": [
        "### Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA0rmS5IbOhv",
        "outputId": "6ed60c9d-a342-4299-c298-9acac640f85d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-12 21:10:15--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/uber_2021.pdf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1880483 (1.8M) [application/octet-stream]\n",
            "Saving to: ‘data/10k/uber_2021.pdf’\n",
            "\n",
            "\rdata/10k/uber_2021.   0%[                    ]       0  --.-KB/s               \rdata/10k/uber_2021. 100%[===================>]   1.79M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-04-12 21:10:15 (77.5 MB/s) - ‘data/10k/uber_2021.pdf’ saved [1880483/1880483]\n",
            "\n",
            "--2024-04-12 21:10:15--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/lyft_2021.pdf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1440303 (1.4M) [application/octet-stream]\n",
            "Saving to: ‘data/10k/lyft_2021.pdf’\n",
            "\n",
            "data/10k/lyft_2021. 100%[===================>]   1.37M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-04-12 21:10:16 (63.0 MB/s) - ‘data/10k/lyft_2021.pdf’ saved [1440303/1440303]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p 'data/10k/'\n",
        "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/uber_2021.pdf' -O 'data/10k/uber_2021.pdf'\n",
        "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/lyft_2021.pdf' -O 'data/10k/lyft_2021.pdf'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlhxgDAhdanb"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3kycd7CbRDe"
      },
      "outputs": [],
      "source": [
        "if not index_loaded:\n",
        "    # load data\n",
        "    lyft_docs = SimpleDirectoryReader(\n",
        "        input_files=[\"./data/10k/lyft_2021.pdf\"]\n",
        "    ).load_data()\n",
        "    uber_docs = SimpleDirectoryReader(\n",
        "        input_files=[\"./data/10k/uber_2021.pdf\"]\n",
        "    ).load_data()\n",
        "\n",
        "    # build index\n",
        "    lyft_index = VectorStoreIndex.from_documents(lyft_docs)\n",
        "    uber_index = VectorStoreIndex.from_documents(uber_docs)\n",
        "\n",
        "    # persist index\n",
        "    lyft_index.storage_context.persist(persist_dir=\"./storage/lyft\")\n",
        "    uber_index.storage_context.persist(persist_dir=\"./storage/uber\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsNt_zZhdcld"
      },
      "source": [
        "### Create Index\n",
        "\n",
        "We will by default use OpenAI Embeddings for building index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hibIsja5bUlb"
      },
      "outputs": [],
      "source": [
        "lyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\n",
        "uber_engine = uber_index.as_query_engine(similarity_top_k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZsjutZYde9R"
      },
      "source": [
        "### Define Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jidXn8xCbXHF"
      },
      "outputs": [],
      "source": [
        "query_engine_tools = [\n",
        "    QueryEngineTool(\n",
        "        query_engine=lyft_engine,\n",
        "        metadata=ToolMetadata(\n",
        "            name=\"lyft_10k\",\n",
        "            description=(\n",
        "                \"Provides information about Lyft financials for year 2021. \"\n",
        "                \"Use a detailed plain text question as input to the tool.\"\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        "    QueryEngineTool(\n",
        "        query_engine=uber_engine,\n",
        "        metadata=ToolMetadata(\n",
        "            name=\"uber_10k\",\n",
        "            description=(\n",
        "                \"Provides information about Uber financials for year 2021. \"\n",
        "                \"Use a detailed plain text question as input to the tool.\"\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju5JLvh9dhXb"
      },
      "source": [
        "#### OpenAI GPT-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KML03j15bbKl"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(model=\"gpt-4\")\n",
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    query_engine_tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    allow_parallel_tool_calls=True,\n",
        ")\n",
        "agent = AgentRunner(agent_worker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVtJB-4wbq-E",
        "outputId": "e0e631bf-a7e4-48ee-a1ea-6901b87d70de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Compare the revenue growth of Uber and Lyft in 2021.\n",
            "=== Calling Function ===\n",
            "Calling function: uber_10k with args: {\"input\": \"What was Uber's revenue growth in 2021?\"}\n",
            "=== Function Output ===\n",
            "Uber's revenue grew by 57% in 2021.\n",
            "=== Calling Function ===\n",
            "Calling function: lyft_10k with args: {\"input\": \"What was Lyft's revenue growth in 2021?\"}\n",
            "=== Function Output ===\n",
            "Lyft's revenue increased by 36% in 2021 compared to the prior year.\n",
            "=== LLM Response ===\n",
            "In 2021, Uber's revenue grew by 57%, while Lyft's revenue increased by 36%. Therefore, Uber had a higher revenue growth compared to Lyft in the same year.\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\n",
        "    \"Compare the revenue growth of Uber and Lyft in 2021.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PypQerhAbreq",
        "outputId": "5e41ffbe-f365-44aa-87c0-5d9d893623e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "assistant: In 2021, Uber's revenue grew by 57%, while Lyft's revenue increased by 36%. Therefore, Uber had a higher revenue growth compared to Lyft in the same year.\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFf1kpWudklG"
      },
      "source": [
        "#### Anthropic Sonnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kVH4Sx5bw2q"
      },
      "outputs": [],
      "source": [
        "llm = Anthropic(model=\"claude-3-sonnet-20240229\")\n",
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    query_engine_tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    allow_parallel_tool_calls=True,\n",
        ")\n",
        "agent = AgentRunner(agent_worker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSOfSijMb2t1",
        "outputId": "9391b008-56d3-4715-a221-9e02a2b3580b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Compare the revenue growth of Uber and Lyft in 2021.\n",
            "=== LLM Response ===\n",
            "Okay, let's use the tools to find information on Uber and Lyft's revenue growth in 2021.\n",
            "=== Calling Function ===\n",
            "Calling function: uber_10k with args: {\"input\": \"What was Uber's revenue growth in 2021?\"}\n",
            "=== Function Output ===\n",
            "Uber's revenue grew by 57% in 2021.\n",
            "=== Calling Function ===\n",
            "Calling function: lyft_10k with args: {\"input\": \"What was Lyft's revenue growth in 2021?\"}\n",
            "=== Function Output ===\n",
            "Lyft's revenue increased by 36% in 2021 compared to the prior year.\n",
            "=== LLM Response ===\n",
            "Based on the information from the tools, Uber had stronger revenue growth of 57% in 2021, compared to Lyft's 36% revenue growth in the same year. So Uber outpaced Lyft in terms of year-over-year revenue growth rate in 2021.\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\n",
        "    \"Compare the revenue growth of Uber and Lyft in 2021.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wyJFAQCb3zZ",
        "outputId": "f3f28698-cc2b-4ff8-f579-3215cbce12d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "assistant: Based on the information from the tools, Uber had stronger revenue growth of 57% in 2021, compared to Lyft's 36% revenue growth in the same year. So Uber outpaced Lyft in terms of year-over-year revenue growth rate in 2021.\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AET5ffzlr88w"
      },
      "source": [
        "### MistralAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ1Ad-LscFHS"
      },
      "outputs": [],
      "source": [
        "llm = MistralAI(model=\"mistral-large-latest\")\n",
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    query_engine_tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    allow_parallel_tool_calls=False,\n",
        ")\n",
        "agent = AgentRunner(agent_worker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtOEyVCkr2iq",
        "outputId": "a1084057-47c1-4f74-89a7-83eee9e4b427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Compare the revenue growth of Uber and Lyft in 2021.\n",
            "=== Calling Function ===\n",
            "Calling function: lyft_10k with args: {\"input\": \"What was the revenue growth of Lyft in 2021?\"}\n",
            "=== Function Output ===\n",
            "Lyft's revenue increased by 36% in 2021 compared to the prior year.\n",
            "=== Calling Function ===\n",
            "Calling function: uber_10k with args: {\"input\": \"What was the revenue growth of Uber in 2021?\"}\n",
            "=== Function Output ===\n",
            "The revenue growth of Uber in 2021 was 57%.\n",
            "=== LLM Response ===\n",
            "In 2021, Uber's revenue growth was 57%, while Lyft's revenue growth was 36%. Therefore, Uber had a higher revenue growth rate compared to Lyft in 2021.\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\n",
        "    \"Compare the revenue growth of Uber and Lyft in 2021.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igwWqCeOr303",
        "outputId": "2f6c6bc8-c4c5-45a2-caec-215203469691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "assistant: In 2021, Uber's revenue growth was 57%, while Lyft's revenue growth was 36%. Therefore, Uber had a higher revenue growth rate compared to Lyft in 2021.\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FXUKH34r69R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
