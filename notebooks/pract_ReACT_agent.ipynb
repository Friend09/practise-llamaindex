{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReACT Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "ELEVENLABS_API_KEY = os.getenv(\"ELEVENLABS_API_KEY\")\n",
    "MISTRALAI_API_KEY = os.getenv(\"MISTRALAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMPLE CALCULATOR TOOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.llms.anthropic import Anthropic\n",
    "from llama_index.llms.mistralai import MistralAI\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.tools import BaseTool, FunctionTool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two integers and returns the result integer\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate tools\n",
    "tool_multiply = FunctionTool.from_defaults(fn=multiply)\n",
    "tool_add = FunctionTool.from_defaults(fn=add)\n",
    "tool_subtract = FunctionTool.from_defaults(fn=subtract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPENAI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_openai = OpenAI(api_key=OPENAI_API_KEY, model=\"gpt-4\")\n",
    "\n",
    "agent_openai = ReActAgent.from_tools(\n",
    "    [tool_multiply, tool_add, tool_subtract], llm=llm_openai, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The user wants to calculate the expression 20+(2*4) step by step. The first step is to calculate the multiplication part of the expression, which is 2*4. I will use the 'multiply' tool for this.\n",
      "Action: multiply\n",
      "Action Input: {'a': 2, 'b': 4}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 8\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: The result of the multiplication 2*4 is 8. Now, I need to add this result to 20. I will use the 'add' tool for this.\n",
      "Action: add\n",
      "Action Input: {'a': 20, 'b': 8}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 28\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. The result of the addition 20+8 is 28, which is the final result of the expression 20+(2*4).\n",
      "Answer: The result of the expression 20+(2*4) is 28.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# get response from agent\n",
    "response_openai = agent_openai.chat(\"What is 20+(2*4)? Calculate step by step.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of the expression 20+(2*4) is 28.\n"
     ]
    }
   ],
   "source": [
    "print(response_openai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANTHROPIC LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_anthropic = Anthropic(api_key=ANTHROPIC_API_KEY, model=\"claude-3-sonnet-20240229\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent_anthropic = ReActAgent.from_tools(\n",
    "    [tool_add, tool_multiply, tool_subtract], llm=llm_anthropic, verbose=True\n",
    ")\n",
    "\n",
    "response_anthropic = agent_anthropic.chat(\"What is 20+(2*4)? Calculate step by step.\")\n",
    "\n",
    "print(response_anthropic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISTRAL LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_mistral = MistralAI(api_key=MISTRALAI_API_KEY, model=\"mistral-large-latest\")\n",
    "agent_mistral = ReActAgent.from_tools(\n",
    "    [tool_add, tool_multiply, tool_subtract], llm=llm_mistral, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response_mistral = agent_mistral.chat(\"What is 20+(2*4)? Calculate step by step.\")\n",
    "print(response_mistral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECK PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: agent_worker:system_prompt\n",
      "\n",
      "Value: You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "{tool_desc}\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of {tool_names}) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "prompt_dict_openai = agent_openai.get_prompts()\n",
    "for k, v in prompt_dict_openai.items():\n",
    "    print(f\"Prompt: {k}\\n\\nValue: {v.template}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "ELEVENLABS_API_KEY = os.getenv(\"ELEVENLABS_API_KEY\")\n",
    "MISTRALAI_API_KEY = os.getenv(\"MISTRALAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG QUERY ENGINE TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    # SimpleDirectoryReader,\n",
    "    # VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.legacy import VectorStoreIndex\n",
    "from llama_index.legacy.readers import SimpleDirectoryReader\n",
    "\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: index means a node, a document can be split up into multiple nodes/chunks\n",
    "try:\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"../data/storage/lyft\")\n",
    "    lyft_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"../data/storage/uber\")\n",
    "    uber_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    index_loaded = True\n",
    "except:\n",
    "    index_loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download data\n",
    "# !mkdir -p '../data/llamaindex/data/10k'\n",
    "# !wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/uber_2021.pdf' -O '../data/llamaindex/data/10k/uber_2021.pdf'\n",
    "# !wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/lyft_2021.pdf' -O '../data/llamaindex/data/10k/lyft_2021.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core import readers\n",
    "\n",
    "if not index_loaded:\n",
    "    lyft_docs = SimpleDirectoryReader(\n",
    "        input_files=[\"../data/llamaindex/data/10k/lyft_2021.pdf\"]\n",
    "    ).load_data()\n",
    "    uber_docs = SimpleDirectoryReader(\n",
    "        input_files=[\"../data/llamaindex/data/10k/uber_2021.pdf\"]\n",
    "    ).load_data()\n",
    "\n",
    "    # build index\n",
    "    lyft_index = VectorStoreIndex.from_documents(lyft_docs)\n",
    "    uber_index = VectorStoreIndex.from_documents(uber_docs)\n",
    "\n",
    "    # persist index\n",
    "    lyft_index.storage_context.persist(persist_dir=\"../data/storage/lyft\")\n",
    "    uber_index.storage_context.persist(persist_dir=\"../data/storage/uber\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\n",
    "uber_engine = uber_index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=lyft_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"lyft_10k\",\n",
    "            description=(\n",
    "                \"Provides information about Lyft financials for year 2021. Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    QueryEngineTool(\n",
    "        query_engine=uber_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"uber_10k\",\n",
    "            description=(\n",
    "                \"Provides information about Uber financials for year 2021. Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_openai = ReActAgent.from_tools(query_engine_tools, llm=llm_openai, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: To compare the revenue growth of Uber and Lyft in 2021, I need to use the uber_10k and lyft_10k tools to get the financial information for each company.\n",
      "Action: uber_10k\n",
      "Action Input: {'input': \"What was Uber's revenue growth in 2021?\"}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Uber's revenue growth in 2021 was 57%.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: Now that I have the revenue growth for Uber, I need to use the lyft_10k tool to get the revenue growth for Lyft in 2021.\n",
      "Action: lyft_10k\n",
      "Action Input: {'input': \"What was Lyft's revenue growth in 2021?\"}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Lyft's revenue increased by 36% in 2021 compared to the prior year.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: In 2021, Uber's revenue growth was 57%, while Lyft's revenue increased by 36%. Therefore, Uber had a higher revenue growth compared to Lyft in 2021.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response_openai = agent_openai.chat(\"Compare the revenue growth of Uber and Lyft in 2021.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2021, Uber's revenue growth was 57%, while Lyft's revenue increased by 36%. Therefore, Uber had a higher revenue growth compared to Lyft in 2021.\n"
     ]
    }
   ],
   "source": [
    "print(response_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use tools to get information about Uber and Lyft's revenue growth in 2021 to answer this question.\n",
      "Action: uber_10k\n",
      "Action Input: {'input': \"What was Uber's revenue growth in 2021?\"}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Uber's revenue growth in 2021 was 57%.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I now have information about Uber's revenue growth in 2021, but still need Lyft's revenue growth to compare the two companies.\n",
      "Action: lyft_10k\n",
      "Action Input: {'input': \"What was Lyft's revenue growth in 2021?\"}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Lyft's revenue increased by 36% in 2021 compared to the prior year.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I now have the revenue growth information for both Uber and Lyft in 2021. I can answer the question without using any more tools.\n",
      "Answer: In 2021, Uber's revenue grew at a faster rate of 57% compared to Lyft's revenue growth of 36%.\n",
      "\u001b[0mIn 2021, Uber's revenue grew at a faster rate of 57% compared to Lyft's revenue growth of 36%.\n"
     ]
    }
   ],
   "source": [
    "agent_anthropic = ReActAgent.from_tools(\n",
    "    tools=query_engine_tools, llm=llm_anthropic, verbose=True\n",
    ")\n",
    "\n",
    "response_anthropic = agent_anthropic.chat(\n",
    "    \"Compare the revenue growth of Uber and Lyft in 2021.\"\n",
    ")\n",
    "\n",
    "print(response_anthropic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use tools to help me answer the question. I will first use the 'lyft_10k' tool to get information about Lyft's revenue in 2021, then use the 'uber_10k' tool to get information about Uber's revenue in 2021.\n",
      "Action: lyft_10k\n",
      "Action Input: {'input': 'What was the revenue of Lyft in 2021?'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Lyft's revenue in 2021 was $3,208,323,000.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: The current language of the user is: English. I have the information about Lyft's revenue in 2021. Now, I need to use the 'uber_10k' tool to get information about Uber's revenue in 2021.\n",
      "Action: uber_10k\n",
      "Action Input: {'input': 'What was the revenue of Uber in 2021?'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: $17,455\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: The current language of the user is: English. I have the information about Uber's and Lyft's revenue in 2021. Now, I can calculate the revenue growth of Uber and Lyft in 2021.\n",
      "\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: Uber's revenue in 2021 was $17,455,000,000 and Lyft's revenue in 2021 was $3,208,323,000. To calculate the revenue growth, I would need the revenue of both companies from the previous year. However, I do not have that information. Therefore, I cannot calculate the revenue growth of Uber and Lyft in 2021.\n",
      "\u001b[0mUber's revenue in 2021 was $17,455,000,000 and Lyft's revenue in 2021 was $3,208,323,000. To calculate the revenue growth, I would need the revenue of both companies from the previous year. However, I do not have that information. Therefore, I cannot calculate the revenue growth of Uber and Lyft in 2021.\n"
     ]
    }
   ],
   "source": [
    "agent_mistral = ReActAgent.from_tools(\n",
    "    tools=query_engine_tools, llm=llm_mistral, verbose=True\n",
    ")\n",
    "\n",
    "response_mistral = agent_mistral.chat(\n",
    "    \"Compare the revenue growth of Uber and Lyft in 2021.\"\n",
    ")\n",
    "print(response_mistral)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
