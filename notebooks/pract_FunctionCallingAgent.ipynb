{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GWvKKFRdxvP"
      },
      "source": [
        "# FunctionCallingAgent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "_ = load_dotenv(find_dotenv())\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "ELEVENLABS_API_KEY = os.getenv(\"ELEVENLABS_API_KEY\")\n",
        "MISTRALAI_API_KEY = os.getenv(\"MISTRALAI_API_KEY\")\n",
        "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SIMPLE CALCULATOR TOOLS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.core.agent import ReActAgent\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.llms.anthropic import Anthropic\n",
        "from llama_index.llms.mistralai import MistralAI\n",
        "from llama_index.core.llms import ChatMessage\n",
        "from llama_index.core.tools import BaseTool, FunctionTool\n",
        "from llama_index.core.agent import FunctionCallingAgentWorker, AgentRunner\n",
        "from llama_index.core.agent import AgentRunner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two integers and returns the result integer\"\"\"\n",
        "    return a * b\n",
        "\n",
        "\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
        "    return a + b\n",
        "\n",
        "\n",
        "def subtract(a: int, b: int) -> int:\n",
        "    \"\"\"Subtract two integers and returns the result integer\"\"\"\n",
        "    return a - b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "tool_multiply = FunctionTool.from_defaults(fn=multiply)\n",
        "tool_add = FunctionTool.from_defaults(fn=add)\n",
        "tool_subtract = FunctionTool.from_defaults(fn=subtract)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm_openai = OpenAI(api_key=OPENAI_API_KEY, model=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: What is 20+(2*4)? Calculate step by step.\n",
            "=== Calling Function ===\n",
            "Calling function: multiply with args: {\"a\": 2, \"b\": 4}\n",
            "=== Function Output ===\n",
            "8\n",
            "=== Calling Function ===\n",
            "Calling function: add with args: {\"a\": 20, \"b\": 8}\n",
            "=== Function Output ===\n",
            "28\n",
            "=== LLM Response ===\n",
            "The calculation steps are as follows:\n",
            "\n",
            "1. First, multiply \\(2\\) by \\(4\\):\n",
            "   \\[\n",
            "   2 \\times 4 = 8\n",
            "   \\]\n",
            "\n",
            "2. Then, add the result to \\(20\\):\n",
            "   \\[\n",
            "   20 + 8 = 28\n",
            "   \\]\n",
            "\n",
            "So, \\(20 + (2 \\times 4) = 28\\).\n"
          ]
        }
      ],
      "source": [
        "agent_worker_openai = FunctionCallingAgentWorker.from_tools(\n",
        "    [tool_multiply, tool_add, tool_subtract],\n",
        "    llm=llm_openai,\n",
        "    verbose=True,\n",
        "    allow_parallel_tool_calls=False,\n",
        ")\n",
        "\n",
        "agent_openai = AgentRunner(agent_worker_openai)\n",
        "\n",
        "response_openai = agent_openai.chat(\"What is 20+(2*4)? Calculate step by step.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The calculation steps are as follows:\n",
            "\n",
            "1. First, multiply \\(2\\) by \\(4\\):\n",
            "   \\[\n",
            "   2 \\times 4 = 8\n",
            "   \\]\n",
            "\n",
            "2. Then, add the result to \\(20\\):\n",
            "   \\[\n",
            "   20 + 8 = 28\n",
            "   \\]\n",
            "\n",
            "So, \\(20 + (2 \\times 4) = 28\\).\n"
          ]
        }
      ],
      "source": [
        "print(response_openai)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: 40 + (100 - 30)*5 ? Calculate step by step.\n",
            "=== Calling Function ===\n",
            "Calling function: subtract with args: {\"a\": 100, \"b\": 30}\n",
            "=== Function Output ===\n",
            "70\n",
            "=== Calling Function ===\n",
            "Calling function: multiply with args: {\"a\": 70, \"b\": 5}\n",
            "=== Function Output ===\n",
            "350\n",
            "=== Calling Function ===\n",
            "Calling function: add with args: {\"a\": 40, \"b\": 350}\n",
            "=== Function Output ===\n",
            "390\n",
            "=== LLM Response ===\n",
            "The calculation steps are as follows:\n",
            "\n",
            "1. First, subtract \\(30\\) from \\(100\\):\n",
            "   \\[\n",
            "   100 - 30 = 70\n",
            "   \\]\n",
            "\n",
            "2. Then, multiply the result by \\(5\\):\n",
            "   \\[\n",
            "   70 \\times 5 = 350\n",
            "   \\]\n",
            "\n",
            "3. Finally, add the result to \\(40\\):\n",
            "   \\[\n",
            "   40 + 350 = 390\n",
            "   \\]\n",
            "\n",
            "So, \\(40 + (100 - 30) \\times 5 = 390\\).\n",
            "The calculation steps are as follows:\n",
            "\n",
            "1. First, subtract \\(30\\) from \\(100\\):\n",
            "   \\[\n",
            "   100 - 30 = 70\n",
            "   \\]\n",
            "\n",
            "2. Then, multiply the result by \\(5\\):\n",
            "   \\[\n",
            "   70 \\times 5 = 350\n",
            "   \\]\n",
            "\n",
            "3. Finally, add the result to \\(40\\):\n",
            "   \\[\n",
            "   40 + 350 = 390\n",
            "   \\]\n",
            "\n",
            "So, \\(40 + (100 - 30) \\times 5 = 390\\).\n"
          ]
        }
      ],
      "source": [
        "response_openai = agent_openai.chat(\"40 + (100 - 30)*5 ? Calculate step by step.\")\n",
        "print(response_openai)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AgentChatResponse(response='The calculation steps are as follows:\\n\\n1. First, subtract \\\\(30\\\\) from \\\\(100\\\\):\\n   \\\\[\\n   100 - 30 = 70\\n   \\\\]\\n\\n2. Then, multiply the result by \\\\(5\\\\):\\n   \\\\[\\n   70 \\\\times 5 = 350\\n   \\\\]\\n\\n3. Finally, add the result to \\\\(40\\\\):\\n   \\\\[\\n   40 + 350 = 390\\n   \\\\]\\n\\nSo, \\\\(40 + (100 - 30) \\\\times 5 = 390\\\\).', sources=[ToolOutput(content='70', tool_name='subtract', raw_input={'args': (), 'kwargs': {'a': 100, 'b': 30}}, raw_output=70, is_error=False), ToolOutput(content='350', tool_name='multiply', raw_input={'args': (), 'kwargs': {'a': 70, 'b': 5}}, raw_output=350, is_error=False), ToolOutput(content='390', tool_name='add', raw_input={'args': (), 'kwargs': {'a': 40, 'b': 350}}, raw_output=390, is_error=False)], source_nodes=[], is_dummy_stream=False)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: What is 20+(2*4)? Calculate step by step.\n",
            "=== LLM Response ===\n",
            "Okay, let's calculate 20 + (2 * 4) step-by-step:\n",
            "=== Calling Function ===\n",
            "Calling function: multiply with args: {\"a\": 2, \"b\": 4}\n",
            "=== Function Output ===\n",
            "8\n",
            "=== LLM Response ===\n",
            "First, we multiply 2 * 4 to get 8.\n",
            "\n",
            "Then:\n",
            "=== Calling Function ===\n",
            "Calling function: add with args: {\"a\": 20, \"b\": 8}\n",
            "=== Function Output ===\n",
            "28\n",
            "=== LLM Response ===\n",
            "We add 20 + 8 to get the final answer of 28.\n",
            "\n",
            "Therefore, the step-by-step calculation of 20 + (2 * 4) is:\n",
            "1) 2 * 4 = 8\n",
            "2) 20 + 8 = 28\n",
            "We add 20 + 8 to get the final answer of 28.\n",
            "\n",
            "Therefore, the step-by-step calculation of 20 + (2 * 4) is:\n",
            "1) 2 * 4 = 8\n",
            "2) 20 + 8 = 28\n"
          ]
        }
      ],
      "source": [
        "llm_anthropic = Anthropic(api_key=ANTHROPIC_API_KEY, model=\"claude-3-sonnet-20240229\")\n",
        "\n",
        "agent_worker_anthropic = FunctionCallingAgentWorker.from_tools(\n",
        "    [tool_multiply, tool_add, tool_subtract],\n",
        "    llm=llm_anthropic,\n",
        "    verbose=True,\n",
        "    allow_parallel_tool_calls=False,\n",
        ")\n",
        "\n",
        "agent_anthropic = AgentRunner(agent_worker_anthropic)\n",
        "response_anthropic = agent_anthropic.chat(\"What is 20+(2*4)? Calculate step by step.\")\n",
        "\n",
        "print(response_anthropic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: What is 20+(2*4)? Calculate step by step.\n",
            "=== Calling Function ===\n",
            "Calling function: multiply with args: {\"a\": 2, \"b\": 4}\n",
            "=== Function Output ===\n",
            "8\n",
            "=== LLM Response ===\n",
            "The first step is to multiply 2 and 4, which gives us 8.\n",
            "Now, we add 20 to 8.\n",
            "\n",
            "So, 20+(2*4) = 20+8 = 28.\n",
            "The first step is to multiply 2 and 4, which gives us 8.\n",
            "Now, we add 20 to 8.\n",
            "\n",
            "So, 20+(2*4) = 20+8 = 28.\n"
          ]
        }
      ],
      "source": [
        "llm_mistral = MistralAI(api_key=MISTRALAI_API_KEY, model=\"mistral-large-latest\")\n",
        "\n",
        "agent_worker_mistral = FunctionCallingAgentWorker.from_tools(\n",
        "    [tool_multiply, tool_add, tool_subtract],\n",
        "    llm=llm_mistral,\n",
        "    verbose=True,\n",
        "    allow_parallel_tool_calls=False,\n",
        ")\n",
        "\n",
        "agent_mistral = AgentRunner(agent_worker_mistral)\n",
        "response_mistral = agent_mistral.chat(\"What is 20+(2*4)? Calculate step by step.\")\n",
        "\n",
        "print(response_mistral)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RAG QUERY ENGINE TOOLS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.core import StorageContext, load_index_from_storage\n",
        "\n",
        "from llama_index.legacy import VectorStoreIndex\n",
        "from llama_index.legacy.readers import SimpleDirectoryReader\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=\"../data/storage/lyft\")\n",
        "    lyft_index = load_index_from_storage(storage_context)\n",
        "\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=\"../data/storage/uber\")\n",
        "    uber_index = load_index_from_storage(storage_context)\n",
        "\n",
        "    index_loaded = True\n",
        "except:\n",
        "    index_loaded = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "# download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not index_loaded:\n",
        "    # load data\n",
        "    lyft_docs = SimpleDirectoryReader(\n",
        "        input_files=[\"../data/10k/lyft_2021.pdf\"]\n",
        "    ).load_data()\n",
        "    uber_docs = SimpleDirectoryReader(\n",
        "        input_files=[\"../data/10k/uber_2021.pdf\"]\n",
        "    ).load_data()\n",
        "\n",
        "    # build index\n",
        "    lyft_index = VectorStoreIndex.from_documents(lyft_docs)\n",
        "    uber_index = VectorStoreIndex.from_documents(uber_docs)\n",
        "\n",
        "    # persist index\n",
        "    lyft_index.storage_context.persist(persist_dir=\"../data/storage/lyft\")\n",
        "    uber_index.storage_context.persist(persist_dir=\"../data/storage/uber\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "lyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\n",
        "uber_engine = uber_index.as_query_engine(similarity_top_k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_engine_tools = [\n",
        "    QueryEngineTool(\n",
        "        query_engine=lyft_engine,  # retreiver\n",
        "        metadata=ToolMetadata(\n",
        "            name=\"lyft_10k\",\n",
        "            description=(\n",
        "                \"Praovides information about Lyft financials for year 2021. Use a detailed plain text question as input to the tool.\"\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        "    QueryEngineTool(\n",
        "        query_engine=uber_engine,\n",
        "        metadata=ToolMetadata(\n",
        "            name=\"uber_10k\",\n",
        "            description=(\n",
        "                \"Provides information about Uber financials for year 2021. Use a detailed plain text question as input to the tool.\"\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm_openai = OpenAI(model=\"gpt-4o\")\n",
        "agent_worker_openai = FunctionCallingAgentWorker.from_tools(\n",
        "    query_engine_tools,\n",
        "    llm=llm_openai,\n",
        "    verbose=True,\n",
        "    allow_parallel_tool_calls=True,\n",
        ")\n",
        "\n",
        "agent_openai = AgentRunner(agent_worker_openai)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Compare the revenue growth of Uber and Lyft in 2021.\n",
            "=== Calling Function ===\n",
            "Calling function: uber_10k with args: {\"input\": \"What was Uber's revenue growth in 2021?\"}\n",
            "=== Function Output ===\n",
            "Uber's revenue growth in 2021 was 57%.\n",
            "=== Calling Function ===\n",
            "Calling function: lyft_10k with args: {\"input\": \"What was Lyft's revenue growth in 2021?\"}\n",
            "=== Function Output ===\n",
            "Lyft's revenue increased by 36% in 2021 compared to the prior year.\n",
            "=== LLM Response ===\n",
            "In 2021, Uber's revenue grew by 57%, while Lyft's revenue increased by 36%.\n"
          ]
        }
      ],
      "source": [
        "response_openai = agent_openai.chat(\n",
        "    \"Compare the revenue growth of Uber and Lyft in 2021.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
