{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented FuctionCallingAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "ELEVENLABS_API_KEY = os.getenv(\"ELEVENLABS_API_KEY\")\n",
    "MISTRALAI_API_KEY = os.getenv(\"MISTRALAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Calculator Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.tools import BaseTool, FunctionTool\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers with and returns the result integer\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two integers with and returns the result integer\"\"\"\n",
    "    return a - b\n",
    "\n",
    "\n",
    "def useless(a: int, b: int) -> int:\n",
    "    \"\"\"Toy useless function.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_multiply = FunctionTool.from_defaults(fn=multiply)\n",
    "tool_add = FunctionTool.from_defaults(fn=add)\n",
    "tool_subtract = FunctionTool.from_defaults(fn=subtract)\n",
    "tools_useless = [\n",
    "    FunctionTool.from_defaults(fn=useless, name=f\"useless_{str(idx)}\")\n",
    "    for idx in range(50)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tool_multiply] + [tool_add] + [tool_subtract] + tools_useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.legacy import VectorStoreIndex\n",
    "from llama_index.legacy.objects import ObjectIndex\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: 299 * 8 + 23\n",
      "=== Calling Function ===\n",
      "Calling function: useless_9 with args: {\"a\": 299, \"b\": 8}\n",
      "=== Function Output ===\n",
      "None\n",
      "=== Calling Function ===\n",
      "Calling function: useless_45 with args: {\"a\": 299, \"b\": 8}\n",
      "=== Function Output ===\n",
      "None\n",
      "=== Calling Function ===\n",
      "Calling function: useless_9 with args: {\"a\": 299, \"b\": 8}\n",
      "=== Function Output ===\n",
      "None\n",
      "=== LLM Response ===\n",
      "It seems the functions I attempted to use are not providing the expected results. I'll calculate the expression manually:\n",
      "\n",
      "First, calculate \\( 299 \\times 8 \\):\n",
      "\\[ 299 \\times 8 = 2392 \\]\n",
      "\n",
      "Next, add 23 to the result:\n",
      "\\[ 2392 + 23 = 2415 \\]\n",
      "\n",
      "So, \\( 299 \\times 8 + 23 = 2415 \\).\n"
     ]
    }
   ],
   "source": [
    "llm_openai = OpenAI(api_key=OPENAI_API_KEY, model=\"gpt-4o\")\n",
    "\n",
    "agent_worker_openai = FunctionCallingAgentWorker.from_tools(\n",
    "    tool_retriever=obj_index.as_retriever(similarity_top_k=2),\n",
    "    llm=llm_openai,\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=False,\n",
    ")\n",
    "\n",
    "agent_openai = AgentRunner(agent_worker_openai)\n",
    "response = agent_openai.chat(\"299 * 8 + 23\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG QUERY ENGINE TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from llama_index.legacy import VectorStoreIndex\n",
    "from llama_index.legacy.readers import SimpleDirectoryReader\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"../data/storage/lyft\")\n",
    "    lyft_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"../data/storage/uber\")\n",
    "    uber_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    index_loaded = True\n",
    "except:\n",
    "    index_loaded = False\n",
    "\n",
    "index_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\n",
    "uber_engine = uber_index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=lyft_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"lyft_10k\",\n",
    "            description=(\n",
    "                \"provides information about lyft financials for year 2021. use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    QueryEngineTool(\n",
    "        query_engine=uber_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"uber_10k\",\n",
    "            description=(\n",
    "                \"Provides information about uber financianls for year 2021. Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_index = ObjectIndex.from_objects(\n",
    "    query_engine_tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is the revenue of Uber in 2021?\n",
      "=== Calling Function ===\n",
      "Calling function: uber_10k with args: {\"input\": \"What is the revenue of Uber in 2021?\"}\n",
      "=== Function Output ===\n",
      "$17,455 million.\n",
      "=== LLM Response ===\n",
      "Uber's revenue in 2021 was $17,455 million.\n",
      "Uber's revenue in 2021 was $17,455 million.\n"
     ]
    }
   ],
   "source": [
    "llm_openai = OpenAI(api_key=OPENAI_API_KEY, model=\"gpt-4o\")\n",
    "\n",
    "agent_worker_openai = FunctionCallingAgentWorker.from_tools(\n",
    "    tool_retriever=obj_index.as_retriever(similarity_top_k=1),\n",
    "    llm=llm_openai,\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=True,\n",
    ")\n",
    "\n",
    "agent_openai = AgentRunner(agent_worker_openai)\n",
    "\n",
    "response_openai = agent_openai.chat(\"What is the revenue of Uber in 2021?\")\n",
    "print(response_openai)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
